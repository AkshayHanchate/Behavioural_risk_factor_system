{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0379b929",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Alcohol' created successfully with columns: ['AVEDRNK3', 'DRNK3GE5', 'MAXDRNKS']\n",
      "Table 'Cancer_test' created successfully with columns: ['HADHYST2', 'CNCRDIFF', 'CNCRAGE', 'CSRVTRT3', 'CSRVDOC1', 'CSRVSUM', 'CSRVRTRN', 'CSRVINST', 'CSRVINSR', 'CSRVDEIN', 'CSRVCLIN', 'CSRVPAIN', 'CSRVCTL2', 'PSATEST1']\n",
      "Table 'Caregiver' created successfully with columns: ['CAREGIV1', 'CRGVREL4', 'CRGVLNG1', 'CRGVHRS1', 'CRGVPRB3', 'CRGVALZD', 'CRGVPER1', 'CRGVHOU1', 'CRGVEXPT']\n",
      "Table 'childhood_exp' created successfully with columns: ['ACEDEPRS', 'ACEDRINK', 'ACEDRUGS', 'ACEPRISN', 'ACEDIVRC', 'ACEPUNCH', 'ACEHURT1', 'ACESWEAR', 'ACETOUCH', 'ACETTHEM', 'ACEHVSEX']\n",
      "Table 'Children_details' created successfully with columns: ['RCSRLTN2', 'CASTHDX2', 'CASTHNO2', 'BIRTHSEX']\n",
      "Table 'Cognitive_Decline' created successfully with columns: ['CIMEMLOS', 'CDHOUSE', 'CDASSIST', 'CDHELP', 'CDSOCIAL', 'CDDISCUS']\n",
      "Table 'Common_Variables ' created successfully with columns: ['_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR', 'DISPCODE', 'SEQNO', '_PSU']\n",
      "Table 'heart_diesease' created successfully with columns: ['CVDINFR4', 'CVDCRHD4', 'CVDSTRK3', 'ASTHMA3', 'ASTHNOW']\n",
      "No matching columns found in the CSV for table 'COVID'.\n",
      "Table 'DERIVED_VARIABLES' created successfully with columns: ['_RFHLTH', '_PHYS14D', '_MENT14D', '_TOTINDA', '_EXTETH3', '_ALTETH3', '_DENVST3', '_MICHD', '_LTASTH1', '_CASTHM1', '_ASTHMS1', '_DRDXAR2', '_HISPANC', '_SEX', '_AGEG5YR', '_AGE65YR', '_AGE80', '_AGE_G', 'HTIN4', 'HTM4', 'WTKG3', '_BMI5', '_BMI5CAT', '_RFBMI5', '_CHLDCNT', '_EDUCAG', '_RFMAM22', '_MAM5023', '_SMOKER3', '_RFSMOK3', '_FLSHOT7', '_PNEUMO3', '_AIDTST4']\n",
      "Table 'DIABETES' created successfully with columns: ['INSULIN1', 'CHKHEMO3', 'EYEEXAM1']\n",
      "Table 'Disability' created successfully with columns: ['DEAF', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES', 'DIFFALON', 'HADMAM', 'HOWLONG']\n",
      "Table 'Extra' created successfully with columns: ['QSTVER', 'QSTLANG', '_METSTAT', '_URBSTAT', 'MSCODE', '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_IMPRACE', '_CHISPNC', '_CLLCPWT', '_DUALUSE', '_DUALCOR', '_LLCPWT2', '_LLCPWT']\n",
      "No matching columns found in the CSV for table 'Family_Planning'.\n",
      "No matching columns found in the CSV for table 'Firearms '.\n",
      "Table 'Health_Care_details' created successfully with columns: ['CHECKUP1']\n",
      "Table 'Health_Details' created successfully with columns: ['PREGNANT', 'WEIGHT2', 'HEIGHT3', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', 'EXERANY2', 'SLEPTIM1', 'ADDEPEV3', 'CHCKDNY2', 'HAVARTH4', 'DIABETE4']\n",
      "Table 'HIV' created successfully with columns: ['HIVTST7', 'HIVTSTD3', 'HIVRISK5']\n",
      "Table 'Identified_As' created successfully with columns: ['SOMALE', 'SOFEMALE', 'TRNSGNDR']\n",
      "Table 'ME_CFS' created successfully with columns: ['TOLDCFS', 'HAVECFS', 'WORKCFS']\n",
      "Table 'Oral_Care' created successfully with columns: ['LASTDEN4', 'RMVTETH4']\n",
      "Table 'Personal_Information' created successfully with columns: ['CTELENM1', 'PVTRESD1', 'COLGHOUS', 'STATERE1', 'LADULT1', 'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'RESPSLCT', 'SAFETIME', 'CTELNUM1', 'CELLFON5', 'CADULT1', 'PVTRESD3', 'CCLGHOUS', 'CSTATE1', 'LANDLINE', 'HHADULT', 'SEXVAR', 'MARITAL', 'EDUCA', 'RENTHOM1', 'VETERAN3', 'EMPLOY1', 'CHILDREN']\n",
      "No matching columns found in the CSV for table 'Reaction_to_race'.\n",
      "Table 'Smoke_Tobacco' created successfully with columns: ['SMOKE100', 'SMOKDAY2', 'USENOW3', 'LCSFIRST', 'LCSLAST', 'LCSNUMCG', 'LASTSMK2', 'STOPSMK2']\n",
      "No matching columns found in the CSV for table 'Social_life_and_health_equity'.\n",
      "Table 'Marijuana_or_not ' created successfully with columns: ['MARIJAN1']\n",
      "Table 'Vaccination ' created successfully with columns: ['HPVADVC4', 'HPVADSHT', 'SHINGLE2', 'FLUSHOT7', 'FLSHTMY3', 'PNEUVAC4', 'TETANUS1']\n",
      "All data successfully loaded into corresponding tables in SQLite.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Paths to your CSV and Excel files\n",
    "csv_file_path = '2020.csv'  \n",
    "excel_file_path = 'Data_Mapping.xlsx'\n",
    "\n",
    "# Load CSV data into a Pandas DataFrame\n",
    "data_2020 = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Load Excel file containing the mapping (Entity -> Tables, Attribute -> Columns)\n",
    "mapping_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Open SQLite connection\n",
    "conn = sqlite3.connect('behavioral_risk_2020.db')\n",
    "\n",
    "# Iterate over unique entities (table names) from the Excel file\n",
    "for entity in mapping_df['Entity'].unique():\n",
    "    # Get the columns (attributes) related to this entity (table)\n",
    "    entity_columns = mapping_df[mapping_df['Entity'] == entity]['Attribute'].tolist()\n",
    "    \n",
    "    # Filter the entity columns that are available in the CSV data\n",
    "    available_columns = [col for col in entity_columns if col in data_2020.columns]\n",
    "    \n",
    "    if available_columns:  # Proceed only if there are available columns\n",
    "        # Subset the CSV data to include only these columns\n",
    "        entity_data = data_2020[available_columns]\n",
    "        \n",
    "        # Store the subset data into a table in SQLite with the name of the entity\n",
    "        entity_data.to_sql(entity, conn, if_exists='replace', index=False)\n",
    "        print(f\"Table '{entity}' created successfully with columns: {available_columns}\")\n",
    "    else:\n",
    "        print(f\"No matching columns found in the CSV for table '{entity}'.\")\n",
    "\n",
    "# Close the SQLite connection\n",
    "conn.close()\n",
    "\n",
    "print(\"All data successfully loaded into corresponding tables in SQLite.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811c12db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Bucket: gcf-v2-sources-892122457228-us-central1>, <Bucket: gcf-v2-uploads-892122457228-us-central1>, <Bucket: on-prem-ingestion-data>]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable within the notebook\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"top-suprstate-438620-h9-7a2effbc371a.json\"\n",
    "\n",
    "# Now proceed with Google Cloud Storage client initialization\n",
    "from google.cloud import storage\n",
    "\n",
    "# Instantiate a Google Cloud Storage client\n",
    "client = storage.Client()\n",
    "\n",
    "# List the buckets in your project\n",
    "buckets = list(client.list_buckets())\n",
    "print(buckets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202757d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Alcohol' uploaded to GCS as 'sql_tables/Alcohol.csv'\n",
      "Table 'Cancer_test' uploaded to GCS as 'sql_tables/Cancer_test.csv'\n",
      "Table 'Caregiver' uploaded to GCS as 'sql_tables/Caregiver.csv'\n",
      "Table 'childhood_exp' uploaded to GCS as 'sql_tables/childhood_exp.csv'\n",
      "Table 'Children_details' uploaded to GCS as 'sql_tables/Children_details.csv'\n",
      "Table 'Cognitive_Decline' uploaded to GCS as 'sql_tables/Cognitive_Decline.csv'\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * FROM Common_Variables ': no such table: Common_Variables",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:2262\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2262\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: Common_Variables",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Iterate through each table and upload data directly to GCS\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table_name \u001b[38;5;129;01min\u001b[39;00m tables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Read the table into a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     table_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSELECT * FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, conn)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Create an in-memory buffer for CSV data\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     csv_buffer \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mStringIO()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:654\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 654\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    655\u001b[0m             sql,\n\u001b[1;32m    656\u001b[0m             index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m    657\u001b[0m             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    658\u001b[0m             coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[1;32m    659\u001b[0m             parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[1;32m    660\u001b[0m             chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    661\u001b[0m             dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    662\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    663\u001b[0m         )\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    666\u001b[0m         _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:2326\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2317\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2324\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2326\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql, params)\n\u001b[1;32m   2327\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:2274\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2273\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2274\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM Common_Variables ': no such table: Common_Variables"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import io\n",
    "\n",
    "# Google Cloud Storage configuration\n",
    "bucket_name = 'on-prem-ingestion-data'  \n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect('behavioral_risk_2020.db')\n",
    "\n",
    "# Get a list of all tables in the SQLite database\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql(query, conn)\n",
    "\n",
    "# Iterate through each table and upload data directly to GCS\n",
    "for table_name in tables['name']:\n",
    "    # Read the table into a Pandas DataFrame\n",
    "    table_data = pd.read_sql(f'SELECT * FROM {table_name}', conn)\n",
    "    \n",
    "    # Create an in-memory buffer for CSV data\n",
    "    csv_buffer = io.StringIO()\n",
    "    \n",
    "    # Write the DataFrame to the buffer in CSV format\n",
    "    table_data.to_csv(csv_buffer, index=False)\n",
    "    \n",
    "    # Set the destination path in GCS (adjust the path as needed)\n",
    "    destination_blob_name = f'sql_tables/{table_name}.csv'\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    \n",
    "    # Upload the buffer's content to GCS\n",
    "    blob.upload_from_string(csv_buffer.getvalue(), content_type='text/csv')\n",
    "    \n",
    "    print(f\"Table '{table_name}' uploaded to GCS as '{destination_blob_name}'\")\n",
    "\n",
    "# Close SQLite connection\n",
    "conn.close()\n",
    "\n",
    "print(\"All tables uploaded successfully to GCS.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f6f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
